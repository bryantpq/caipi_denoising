{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3e0fe-0c8d-4e39-b551-463725354456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "import sys\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append('/home/quahb/caipi_denoising/src')\n",
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/home/quahb/.conda/pkgs/cuda-nvcc-12.1.105-0'\n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from modeling.DiffusionModel import build_model, DiffusionModel\n",
    "from preparation.prepare_tf_dataset import np_to_tfdataset\n",
    "from preparation.data_io import load_dataset\n",
    "from preparation.preprocessing_pipeline import fourier_transform, inverse_fourier_transform, low_pass_filter, rescale_magnitude\n",
    "from utils.dct import dct2, idct2\n",
    "from utils.GaussianDiffusion import GaussianDiffusion\n",
    "from utils.vizualization_tools import plot2, plot4, plot_slices, plot_patches\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3bd044-12c7-4371-ae06-7c17a868abc5",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57603a0-838e-4652-b5ad-8a6a1a29ed9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "inference_batch_size = 16\n",
    "num_epochs = 501\n",
    "total_timesteps = 1000\n",
    "norm_groups = 8  # Number of groups used in GroupNormalization layer\n",
    "learning_rate = 2e-4\n",
    "image_embedding = True\n",
    "\n",
    "img_size = 384 \n",
    "img_channels = 1\n",
    "\n",
    "first_conv_channels = 64\n",
    "channel_multiplier = [1, 2, 4, 8]\n",
    "widths = [first_conv_channels * mult for mult in channel_multiplier]\n",
    "has_attention = [False, False, True, True]\n",
    "num_res_blocks = 2  # Number of residual blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402850d1-9ced-4cdd-a8b4-58d918ff471b",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a9ea4-559b-4852-97dd-ee4c0baf90c4",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12db6d-0571-4de6-8640-8832c06377bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = load_dataset('/home/quahb/caipi_denoising/data/datasets/unaccelerated/full_magnitude/images/', 2, 'full')\n",
    "images = images[:8000]\n",
    "print(images.shape)\n",
    "\n",
    "tf_images = np_to_tfdataset(images, batch_size=train_batch_size)\n",
    "train_ds = tf_images\n",
    "\n",
    "train_ds = (\n",
    "    tf_images.prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f55e2-4351-45e6-88be-0d458592fb59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabad1b-37a3-472b-80ba-fc81c2989fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_epoch = 0\n",
    "diffusion_model_name = f'diffusion_models/diffusion_ep{load_epoch}.hd5'\n",
    "ema_diffusion_model_name = f'diffusion_models/ema_diffusion_ep{load_epoch}.hd5'\n",
    "\n",
    "# Build the unet model\n",
    "gpus = ['/GPU:0', '/GPU:1', '/GPU:2', '/GPU:3']\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpus)\n",
    "with strategy.scope():\n",
    "    network = build_model(\n",
    "        img_size=img_size,\n",
    "        img_channels=img_channels,\n",
    "        widths=widths,\n",
    "        has_attention=has_attention,\n",
    "        num_res_blocks=num_res_blocks,\n",
    "        norm_groups=norm_groups,\n",
    "        activation_fn=keras.activations.swish,\n",
    "        image_embedding=image_embedding,\n",
    "    )\n",
    "    ema_network = build_model(\n",
    "        img_size=img_size,\n",
    "        img_channels=img_channels,\n",
    "        widths=widths,\n",
    "        has_attention=has_attention,\n",
    "        num_res_blocks=num_res_blocks,\n",
    "        norm_groups=norm_groups,\n",
    "        activation_fn=keras.activations.swish,\n",
    "        image_embedding=image_embedding,\n",
    "    )\n",
    "\n",
    "    if load_epoch == 0:\n",
    "        ema_network.set_weights(network.get_weights())  # Initially the weights are the same\n",
    "    else:\n",
    "        network.load_weights(diffusion_model_name)\n",
    "        ema_network.load_weights(ema_diffusion_model_name)\n",
    "\n",
    "\n",
    "    # Get an instance of the Gaussian Diffusion utilities\n",
    "    gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "    # Get the model\n",
    "    model = DiffusionModel(\n",
    "        network=network,\n",
    "        ema_network=ema_network,\n",
    "        gdf_util=gdf_util,\n",
    "        timesteps=total_timesteps,\n",
    "        image_embedding=image_embedding\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    )\n",
    "    \n",
    "model.network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c02bd-5889-48ab-991c-6fea1c463578",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_date = datetime.date.today()\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=train_batch_size,\n",
    "    initial_epoch=load_epoch,\n",
    "    callbacks=[\n",
    "        keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n",
    "        keras.callbacks.LambdaCallback(on_epoch_end=model.save_model), \n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70726ddc-d192-4fad-9f32-ef9e33c07fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.plot_images(num_rows=5, num_cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c20ee2-3bea-4782-a53e-ee73dbd05860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
