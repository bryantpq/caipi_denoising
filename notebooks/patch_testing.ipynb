{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77af54d0-8a4c-4ceb-81ec-76fa40628631",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Subsample extracted patches using extraction step - DONE\n",
    "\n",
    "Subsample extracted patches using extraction step on padded image - DONE\n",
    "\n",
    "Reconstruct padded image using all patches - DONE\n",
    "\n",
    "Reconstruct image using all patches - DONE\n",
    "\n",
    "Reconstruct image using subsampled patches - IMPOSSIBLE <br>\n",
    " -> During inference, we extract and predict on all patches then reconstruct using all patches <br>\n",
    " -> Might be beneficial since averaging might improve things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4acf7e74-f624-4e56-8b6f-b013c31ea48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10001 % 1000 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d47239-b5c6-46ac-8a3d-e24755ac46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((100, 64, 64, 1))\n",
    "b = np.zeros((100, 64, 64, 1))\n",
    "c = np.zeros((100, 64, 64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "006cedcd-9f12-4565-b5f0-13af23106b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 64, 64, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([a,b,c]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e5628c-7b99-426b-9bde-15095682b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from preparation.preprocessing_pipeline import preprocess_data, extract_patches\n",
    "import sklearn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3456ca55-932f-4be7-8d60-d1e850ebc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation.gen_data import get_data_dict, get_train_data, get_median_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ff6a1b-81ff-4a93-b2b1-8eb19bed5763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16128, 384, 312, 1), (16128, 384, 312, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_train_data()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c33eb1-4e68-4cbf-9566-744c3098dc77",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type 'float8' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type 'float8' not understood"
     ]
    }
   ],
   "source": [
    "X.astype('float8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab91da5-7aeb-430a-9d35-7bf6f32acccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_params = {\n",
    "    'normalize': {},\n",
    "    \n",
    "    'pad_square': {\n",
    "        'value': 0.0\n",
    "    },\n",
    "    \n",
    "    'white_noise': {\n",
    "        'mu': 0.0,\n",
    "        'sigma': 0.15\n",
    "    },\n",
    "    \n",
    "    'extract_patches': {\n",
    "        'patch_size': (32, 32),\n",
    "        'extract_step': (32, 32),\n",
    "        'pad_before_ext': True\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "X_ops = ['normalize', 'pad_square', 'white_noise', 'extract_patches']\n",
    "y_ops = ['normalize', 'pad_square', 'extract_patches']\n",
    "\n",
    "X_train_pp_pat, y_train_pp_pat = train_preprocess(X[:10], y[:10], preprocessing_params,\n",
    "                                                  X_ops=X_ops,\n",
    "                                                  y_ops=y_ops\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e83a51-b4bf-46b8-888b-7db1264a05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp_img, y_train_pp_img = train_preprocess(X[120:125], y[120:125],\n",
    "                                          X_ops=['normalize', 'pad_square', 'white_noise'],\n",
    "                                          y_ops=['normalize', 'pad_square']\n",
    "                                        )\n",
    "X_train_pp_img.shape, y_train_pp_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5f715-de77-4ac7-9649-7cd3f1dc7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp_pat.shape, X_train_pp_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485b8ed-04de-4e02-9d5e-916307902ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "\n",
    "plt.figure(figsize=(25,50))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train_pp_pat[i], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X_train_pp_pat[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c6527-4082-4211-89d3-25eebad81426",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "\n",
    "plt.figure(figsize=(25,50))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train_pp_img[i], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y_train_pp_img[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c78198-ad07-47bf-98b0-bf9bc7a86639",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e96d-67f9-4d44-abb2-a1aff44898dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X[120])\n",
    "\n",
    "plt_i = 1\n",
    "for i in patches[:100]:\n",
    "    plt.subplot(8, 7, plt_i)\n",
    "    plt.imshow(i)\n",
    "    plt_i += 1\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(X[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06871de5-9a84-416d-ae3c-a9f4e67cf640",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X[120])\n",
    "\n",
    "plt_i = 1\n",
    "for i in patches[:20]:\n",
    "    plt.subplot(4, 4, plt_i)\n",
    "    plt.imshow(i)\n",
    "    plt_i += 1\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(X[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c76f69-b409-42f3-abae-fd630019ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(patches[60279, :, :], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(patches[60278, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ec918-b184-456d-b9d1-533eae132692",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_patches = patches[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6448d3d-1562-4085-8619-8442329a937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patches.shape)\n",
    "print(sub_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f176f-8f56-4f2f-9b8b-0ce456663685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_recon_img = sklearn.feature_extraction.image.reconstruct_from_patches_2d(sub_patches, (384, 312))\n",
    "recon_img = sklearn.feature_extraction.image.reconstruct_from_patches_2d(patches, (384, 312))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b406c-0046-470e-b8e3-5f47842f30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(sub_patches[0, :, :], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(sub_patches[1, :, :], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(sub_patches[2, :, :], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(sub_patches[3, :, :], cmap='gray')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(sub_recon_img, cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(recon_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba7c05-d85c-433c-ad4f-d70667cf77f1",
   "metadata": {},
   "source": [
    "0 - [0, 99]\n",
    "1 - [1, 100]\n",
    "...\n",
    "212 - [212, 311]\n",
    "213 - [213, 312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3ea3f-05c5-4ba6-87d3-57e402a58606",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.reshape(np.arange(100), (10, 10))\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc966057-76f9-4d95-9ae6-21a182b023b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# images is a 1 x 10 x 10 x 1 array that contains the numbers 1 through 100\n",
    "images = np.reshape(np.arange(100), (1, 10, 10, 1))\n",
    "\n",
    "# We generate two outputs as follows:\n",
    "# 1. 3x3 patches with stride length 5\n",
    "# 2. Same as above, but the rate is increased to 2\n",
    "images_res = tf.image.extract_patches(images=images,\n",
    "                       sizes=[1, 3, 3, 1],\n",
    "                       strides=[1, 5, 5, 1],\n",
    "                       rates=[1, 1, 1, 1],\n",
    "                       padding='VALID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee72772-18a2-4250-a22b-96457b1237f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82606be9-bd0b-45ff-9a1c-b6a6bad73c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da810e36-df67-4b32-b70c-422f61dbdc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_i = [1, 5]\n",
    "\n",
    "for i in patch_i:\n",
    "    print(images_res[0,:,:,i])\n",
    "    plt.figure()\n",
    "    plt.imshow(images_res[0,:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d07a4-95bb-4851-ba25-fd7f6c731bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
